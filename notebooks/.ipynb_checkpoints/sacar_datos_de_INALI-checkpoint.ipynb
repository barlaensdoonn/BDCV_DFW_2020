{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "extraer datos de páginas de INALI sobre clasificación geográfica de lenguas indígenas\n",
    "base URL: https://www.inali.gob.mx/clin-inali/\n",
    "creado por Brandon Aleson 4/22/20\n",
    "versión actualizado 5/31/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada vez que hacemos una toca al inali.cob.mx, recibimos una alarma así:\n",
    "# InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised.\n",
    "# creo q los certificados de INALI se han caducado\n",
    "# por no ver la alarma cada vez que agarramos un vínculo de INALI, la deshabilitamos aquí\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agrup_urls(caldo, base_url):\n",
    "    '''\n",
    "    por suerte todos los vínculos de agrupaciones lingüísticas\n",
    "    se encuentran entre \"rows\" <tr></tr> en el base_url\n",
    "    '''\n",
    "    vinc_trs = caldo.find_all('tr')\n",
    "    agrup_vincs = []\n",
    "    \n",
    "    # extraer los objetos que tienen el parte \"href\"\n",
    "    for tr in vinc_trs:\n",
    "        agrup_vincs.extend(tr.find_all('a'))\n",
    "    print('ha sacado {} vinculos de agrupaciones lingüísticas en {}'.format(len(agrup_vincs), base_url))\n",
    "    \n",
    "    # construimos los URLs completos\n",
    "    return [os.path.join(base_url, agrup_vinc['href']) for agrup_vinc in agrup_vincs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_agrup_y_familia(sopa):\n",
    "    '''\n",
    "    @sopa: debe ser la página de un nivel más alto que la que\n",
    "           tiene todos los datos específicos de los variantes\n",
    "           por ejemplo: https://www.inali.gob.mx/clin-inali/html/l_nahuatl.html\n",
    "    'agrup' significa la Agrupación lingüística\n",
    "    'familia' significa la Familia lingüística\n",
    "    '''\n",
    "    ling_queridos = []\n",
    "    ling_indexes = {\n",
    "        'agrupación': 0,\n",
    "        'familia': -1\n",
    "    }\n",
    "\n",
    "    for key, value in ling_indexes.items():\n",
    "        ling_querido = sopa.body.h4.contents[value].split(':')[-1].strip()\n",
    "        print('ha sacado el dato tipo {} de la sopa HTML: {}'.format(key, ling_querido))\n",
    "        ling_queridos.append(ling_querido)\n",
    "    return ling_queridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_autodes(td):\n",
    "    '''\n",
    "    @td: debe ser el primer table de una row, en el que queda las autodenominaciones y el variante\n",
    "    \n",
    "    NOTA: este método de extraer las autodenominaciones presupone que siempre hay dos\n",
    "    maneras de describir las autods: primero como string y luego lo mismo de otra forma en brackets.\n",
    "    entonces lo separamos con un newline '\\n' como aparece en la página de INALI\n",
    "    \n",
    "    parace que el variante no queda entre \"paragraph HTML tags\" mientras las autodenominaciones sí\n",
    "    así que sacamos los autodes por buscar todos los paragraph tags <p></p> en el table\n",
    "    '''\n",
    "    pstrings = []\n",
    "    for p in td.find_all('p'):\n",
    "        for pstr in p.strings:\n",
    "            pstrings.append(pstr.strip())\n",
    "\n",
    "    autodes = []\n",
    "    for i in range(len(pstrings)):\n",
    "        if (i+1) % 2 == 0:\n",
    "            autode = '/n'.join([pstrings[i-1], pstrings[i]])\n",
    "            autodes.append(autode)\n",
    "    print('autodenominaciones extraidos del table: {}'.format(autodes))\n",
    "    return autodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacar_variante(td):\n",
    "    variante = td.contents[-1].strip()\n",
    "    print('variante extraido del table: {}'.format(variante))\n",
    "    return variante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datos_geos(datos_geos):\n",
    "    '''@datos_geo debe ser un table de HTML'''\n",
    "    repr_geo = {}\n",
    "    \n",
    "    for parte in datos_geos:\n",
    "        # primero identificamos el estado, que siempre está en mayúsculas\n",
    "        # esta parte del table is of class 'bs4.element.NavigableString'\n",
    "        if parte.__class__ == bs4.element.NavigableString:\n",
    "            if parte.isupper():\n",
    "                estado = parte.strip(' :\\t\\r\\n')\n",
    "                repr_geo[estado] = {}\n",
    "                continue\n",
    "                \n",
    "        # luego, si el parte tiene los bold HTML tags \"<br></br>\"\n",
    "        # es otro tipo de bs4 object of class 'bs4.element.Tag'\n",
    "        if parte.__class__ == bs4.element.Tag and parte.decode().strip() != '<br/>':\n",
    "            municipio = parte.text\n",
    "            repr_geo[estado][municipio] = []\n",
    "            \n",
    "        # los localidades también son de la class 'bs4.element.NavigableString'\n",
    "        # si ya tenemos el estado, sabemos que esta parte describe localidades\n",
    "        if parte.__class__ == bs4.element.NavigableString and repr_geo['estado']:\n",
    "            localidades = parte.strip(' :\\n')\n",
    "            repr_geo[estado][municipio].extend([localidades])\n",
    "\n",
    "        # si hay multiples estados en los que se hablan la misma variante\n",
    "        # van a ser separados por \"linebreaks\". entonces usamos el linebreak\n",
    "        # como un flag para identificar que hay que construir otro repr_geo nuevo\n",
    "        if parte.__class__ == bs4.element.Tag and parte.decode().strip() == '<br/>':\n",
    "            yield repr_geo\n",
    "            repr_geo = {}\n",
    "    \n",
    "    # yield el último\n",
    "    print('hemos extraido todos los datos geográficos de este table')\n",
    "    yield repr_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output nuestro trabajo para compartir\n",
    "def output_variante_json(datos):\n",
    "    '''construir un filename del nombre de variante y escribir los datos a un archivo de JSON'''\n",
    "    variante_split = datos['variante'].strip('<>').split(' ')\n",
    "    datos_file_ending = ('_').join([vsplit.strip(',') for vsplit in variante_split])\n",
    "    \n",
    "    # crear una carpeta por la agrupación si no existe\n",
    "    outpath = os.path.join('output', datos['agrupacion_lingüística'])\n",
    "    try:\n",
    "        os.makedirs(outpath)\n",
    "        print('created directory {}'.format(outpath))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    outfile = os.path.join(outpath, 'datos_de_{}.json'.format(datos_file_ending))\n",
    "    print('escribiendo los datos del variante {} a \"{}\"'.format(datos_file_ending, outfile))\n",
    "    with open(outfile, 'w') as outf:\n",
    "        outf.write(json.dumps(datos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es el URL donde se encuentra todos los vínculos de las agrupaciones lingüísticas\n",
    "# ver aquí más detalle sobre \"verify\" y certificates:\n",
    "# https://stackoverflow.com/questions/28667684/python-requests-getting-sslerror\n",
    "base_url = 'https://www.inali.gob.mx/clin-inali/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha sacado 68 vinculos de agrupaciones lingüísticas en https://www.inali.gob.mx/clin-inali/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.inali.gob.mx/clin-inali/html/l_akateko.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sacamos todos los URLs de agrupaciones lingüísticas que hay en el base_url\n",
    "r = requests.get(base_url, verify=False)\n",
    "caldo = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "agrup_urls = get_agrup_urls(caldo, base_url)\n",
    "agrup_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### la agrupación y la familia lingüística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha sacado el dato tipo agrupación de la sopa HTML: Akateko\n",
      "ha sacado el dato tipo familia de la sopa HTML: Maya\n",
      "agrupacion: Akateko; familia: Maya\n"
     ]
    }
   ],
   "source": [
    "# empezamos en esta página (l_<variante>.html) para agarrar\n",
    "# la información de Agrupación y Familia Lingüística\n",
    "r = requests.get(agrup_urls[0], verify=False)\n",
    "sopa = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "agrup_ling, familia_ling = sacar_agrup_y_familia(sopa)\n",
    "print('agrupacion: {}; familia: {}'.format(agrup_ling, familia_ling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construimos el vínculo de la agrupación y la exploramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.inali.gob.mx/clin-inali/html/v_akateko.html#1\n"
     ]
    }
   ],
   "source": [
    "# ya tenemos los datos que necesitamos de esta página,\n",
    "# seguimos a un nivel más bajo, las agrupaciónes lingüísticas\n",
    "# sabemos que todos los vínculos de una página Agrupación/Familia Lingüística\n",
    "# nos llevan a la misma página que tiene todos los variantes de ese grupo\n",
    "# entonces construimos el URL de una agrupación lingüística entera \n",
    "# y seguimos sacando los datos de los variantes\n",
    "var_url = ''.join([base_url, 'html/', sopa.body.a.attrs['href']])\n",
    "print(var_url)\n",
    "r = requests.get(var_url, verify=False)\n",
    "guisado = bs4.BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hay 1 variante(s) en esta agrupación lingüística\n"
     ]
    }
   ],
   "source": [
    "# los datos éspecificos que buscamos aparacen \n",
    "# entre los \"rows\" <tr></tr> tags que hay en una página\n",
    "# por ejemplo la página de nahuatl tiene 31 rows\n",
    "all_trs = guisado.find_all('tr')\n",
    "all_trs.pop(0)  # (la primera row (representado por all_trs[0]) no nos importa porque no tiene un table)\n",
    "print('hay {} variante(s) en esta agrupación lingüística'.format((len(all_trs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td>\n",
       "<p>Kuti’\n",
       "                                <br/>[kutiʔ]</p>\n",
       "                                &lt;Akateko&gt;\n",
       "                                        </td>\n",
       "<td>\n",
       "                                            CAMPECHE: <b>Champotón</b>: Maya Tecún I, Santo Domingo Kesté.\n",
       "                                            \n",
       "                        <br/><br/>\n",
       "                        CHIAPAS: <b>Frontera Comalapa</b>: Nuevo Tres Lagunas. <b>La Trinitaria</b>: Ejido la Gloria 2, Nueva Libertad el Colorado, San Francisco de Asís.\n",
       "                                            \n",
       "                        <br/><br/>\n",
       "                        QUINTANA ROO: <b>Othón P. Blanco</b>: Maya Balam, San Isidro la Laguna.\n",
       "                            </td>\n",
       "</tr>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# para ver un ejemplo\n",
    "all_trs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>\n",
       " <p>Kuti’\n",
       "                                 <br/>[kutiʔ]</p>\n",
       "                                 &lt;Akateko&gt;\n",
       "                                         </td>, <td>\n",
       "                                             CAMPECHE: <b>Champotón</b>: Maya Tecún I, Santo Domingo Kesté.\n",
       "                                             \n",
       "                         <br/><br/>\n",
       "                         CHIAPAS: <b>Frontera Comalapa</b>: Nuevo Tres Lagunas. <b>La Trinitaria</b>: Ejido la Gloria 2, Nueva Libertad el Colorado, San Francisco de Asís.\n",
       "                                             \n",
       "                         <br/><br/>\n",
       "                         QUINTANA ROO: <b>Othón P. Blanco</b>: Maya Balam, San Isidro la Laguna.\n",
       "                             </td>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# más específicamente, los datos del los lenguajes quedan dentro\n",
    "# de los tables que así mismos están dentro de un \"row\"\n",
    "# es decir, encontramos los datos que nos interesa entre los tags <td></td>\n",
    "all_tds = all_trs[0].find_all('td')\n",
    "all_tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Kuti’\n",
       "                                 <br/>[kutiʔ]</p>, '\\n                                <Akateko>\\n                                        ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tds[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kuti’\\n                                [kutiʔ]\\n                                <Akateko>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sabemos que lo que está dentro del primer \"table\" (td tags) son,\n",
    "# en primer lugar, las autodenominaciones, y después el variante\n",
    "all_tds[0].text.strip().split('\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### las autodenominaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autodenominaciones extraidos del table: ['Kuti’/n[kutiʔ]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kuti’/n[kutiʔ]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sacamos las autodenominaciones\n",
    "autodes = sacar_autodes(all_tds[0])\n",
    "autodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### el variante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variante extraido del table: <Akateko>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<Akateko>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sacamos el variante\n",
    "variante = sacar_variante(all_tds[0])\n",
    "variante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### los datos geográficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kuti’\n",
      "[kutiʔ]\n",
      "<Akateko>\n",
      "CAMPECHE:\n",
      "Champotón\n",
      ": Maya Tecún I, Santo Domingo Kesté.\n",
      "CHIAPAS:\n",
      "Frontera Comalapa\n",
      ": Nuevo Tres Lagunas.\n",
      "La Trinitaria\n",
      ": Ejido la Gloria 2, Nueva Libertad el Colorado, San Francisco de Asís.\n",
      "QUINTANA ROO:\n",
      "Othón P. Blanco\n",
      ": Maya Balam, San Isidro la Laguna.\n"
     ]
    }
   ],
   "source": [
    "for td in all_tds:\n",
    "    for string in td.strings:\n",
    "        print(string.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ya vimos que el primer table fue el que tiene la información sobre la autodenominacines y el variante, así que el segundo table deben corresponder a un estado, sus municipios, y luego sus localidades donde se hablan este variante. Si hay más que un estado en donde se hable este variante, estan separados en la pagina con un \"linebreak\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>\n",
       "                                            CAMPECHE: <b>Champotón</b>: Maya Tecún I, Santo Domingo Kesté.\n",
       "                                            \n",
       "                        <br/><br/>\n",
       "                        CHIAPAS: <b>Frontera Comalapa</b>: Nuevo Tres Lagunas. <b>La Trinitaria</b>: Ejido la Gloria 2, Nueva Libertad el Colorado, San Francisco de Asís.\n",
       "                                            \n",
       "                        <br/><br/>\n",
       "                        QUINTANA ROO: <b>Othón P. Blanco</b>: Maya Balam, San Isidro la Laguna.\n",
       "                            </td>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdatos = all_tds[1]\n",
    "gdatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMPECHE\n",
      "<b>Champotón</b>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'estado'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bdd7a447e86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# algunos dictionaries de esta función serán vacias (por los linebreaks),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# por eso filtramos la lista con \"if geo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrepr_geo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgeo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_datos_geos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdatos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrepr_geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-bdd7a447e86a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# algunos dictionaries de esta función serán vacias (por los linebreaks),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# por eso filtramos la lista con \"if geo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrepr_geo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgeo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgeo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparse_datos_geos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdatos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrepr_geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-cdc805b61cd5>\u001b[0m in \u001b[0;36mparse_datos_geos\u001b[0;34m(datos_geos)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# los localidades también son de la class 'bs4.element.NavigableString'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# si ya tenemos el estado, sabemos que esta parte describe localidades\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mparte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNavigableString\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrepr_geo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estado'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mlocalidades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' :\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mrepr_geo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestado\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmunicipio\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocalidades\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'estado'"
     ]
    }
   ],
   "source": [
    "# algunos dictionaries de esta función serán vacias (por los linebreaks),\n",
    "# por eso filtramos la lista con \"if geo\"\n",
    "repr_geo = [geo for geo in parse_datos_geos(gdatos) if geo]\n",
    "repr_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ya tenemos todos los datos que queremos para hacer un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrup_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "familia_ling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### podemos representar los datos con un modelo de JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_de_un_variante = {\n",
    "    'agrupacion_lingüística': '',\n",
    "    'familia_lingüística': '',\n",
    "    'autodenominaciones': [],\n",
    "    'variante': '',\n",
    "    'representación_geográfica': [{}]  # esta es una lista de dictionaries porque un variante puede ser hablado en estados múltiples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando este ejemplo llegamos al siguiente\n",
    "datos_del_variante = {\n",
    "    'agrupacion_lingüística': agrup_ling,\n",
    "    'familia_lingüística': familia_ling,\n",
    "    'autodenominaciones': autodes,\n",
    "    'variante': variante,\n",
    "    'representación_geográfica': repr_geo\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datos_del_variante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actualmente ya tenemos todos los datos, entonces los escribimos a un JSON file\n",
    "output_variante_json(datos_del_variante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # colocamos todos los \"rows\", y descartamos la primera que no tiene información importante\n",
    "# all_trs = sopa.find_all('tr')\n",
    "# all_trs.pop(0)  # (la primera row (representado por all_trs[0]) no nos importa porque no tiene un table)\n",
    "# print('hay {} variantes en esta agrupación lingüística'.format((len(all_trs))))\n",
    "\n",
    "# # ya vamos row por row, y table por table dentro del row\n",
    "# for tr in all_trs:\n",
    "#     all_tds = tr.find_all('td')\n",
    "#     autodes = sacar_autodes(all_tds[0])\n",
    "#     variante = sacar_variante(all_tds[0])\n",
    "#     repr_geo = [geo for geo in parse_datos_geos(all_tds[1]) if geo]\n",
    "    \n",
    "#     datos_del_variante = {\n",
    "#         'agrupacion_lingüística': agrup_ling,\n",
    "#         'familia_lingüística': familia_ling,\n",
    "#         'autodenominaciones': autodes,\n",
    "#         'variante': variante,\n",
    "#         'representación_geográfica': repr_geo\n",
    "#     }\n",
    "\n",
    "#     output_variante_json(datos_del_variante)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://www.inali.gob.mx/clin-inali/html/v_chuj.html#1 está echando una excpeción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.inali.gob.mx/clin-inali/html/v_chuj.html#1'\n",
    "r = requests.get(url, verify=False)\n",
    "sopa = bs4.BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trs = sopa.find_all('tr')\n",
    "all_trs.pop(0)  # (la primera row (representado por all_trs[0]) no nos importa porque no tiene un table)\n",
    "print('hay {} variante(s) en esta agrupación lingüística'.format((len(all_trs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tds = all_trs[0].find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacar_autodes(all_tds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacar_variante(all_tds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdatos = all_tds[1]\n",
    "gdatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repr_geo = [geo for geo in parse_datos_geos(gdatos) if geo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for geo in parse_datos_geos(gdatos):\n",
    "    print(geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                            CAMPECHE: \n",
      "break\n",
      "<b>Champotón</b>\n",
      "break\n",
      ": Maya Tecún I, Santo Domingo Kesté.\n",
      "                                            \n",
      "                        \n",
      "break\n",
      "<br/>\n",
      "break\n",
      "<br/>\n",
      "break\n",
      "\n",
      "                        CHIAPAS: \n",
      "break\n",
      "<b>Frontera Comalapa</b>\n",
      "break\n",
      ": Nuevo Tres Lagunas. \n",
      "break\n",
      "<b>La Trinitaria</b>\n",
      "break\n",
      ": Ejido la Gloria 2, Nueva Libertad el Colorado, San Francisco de Asís.\n",
      "                                            \n",
      "                        \n",
      "break\n",
      "<br/>\n",
      "break\n",
      "<br/>\n",
      "break\n",
      "\n",
      "                        QUINTANA ROO: \n",
      "break\n",
      "<b>Othón P. Blanco</b>\n",
      "break\n",
      ": Maya Balam, San Isidro la Laguna.\n",
      "                            \n",
      "break\n"
     ]
    }
   ],
   "source": [
    "for parte in gdatos:\n",
    "    print(parte)\n",
    "    print('break')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
